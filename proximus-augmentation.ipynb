{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgrpnwhFuUeK"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfnFuZa9urSO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload() # you should have generate an API taken from kaggle/settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5lMmM0Pu1Qj"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0bOuSIdvHa1"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN-O7xDqvSt6"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c 'ada-image-recognition-fiber'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng7r6LugvojH"
      },
      "outputs": [],
      "source": [
        "!mkdir ada-image-recognition-fiber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOuA7lqDv_42"
      },
      "outputs": [],
      "source": [
        "!unzip ada-image-recognition-fiber.zip -d ada-image-recognition-fiber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n-428UVXZDz"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/albumentations-team/albumentations.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3tKKGUMXdVv"
      },
      "outputs": [],
      "source": [
        "target_file = \"albumentations/albumentations/core/bbox_utils.py\"\n",
        "text_to_find = \"return convert_bboxes_to_albumentations(data, self.params.format, rows, cols, check_validity\"\n",
        "lines = None\n",
        "with open(target_file) as f:\n",
        "    lines = f.readlines()\n",
        "    for i, l in enumerate(lines):\n",
        "        if text_to_find in l:\n",
        "            lines[i] = l.replace(\"True\", \"False\")\n",
        "with open(target_file, 'w') as file:\n",
        "    file.writelines(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1MS0mOBX1z6",
        "outputId": "e2b15902-bce1-4954-9d3f-0df3e703e393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: albumentations 1.2.1\n",
            "Uninstalling albumentations-1.2.1:\n",
            "  Successfully uninstalled albumentations-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall albumentations --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl93CMNlXjx8",
        "outputId": "eb6b3f01-648a-43b5-b59c-28088c755ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./albumentations\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (6.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (0.0.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (4.7.0.72)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.5.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.7.0.72)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (1.2.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (23.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2023.4.12)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2.25.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (8.4.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (3.1.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-1.3.0-py3-none-any.whl size=125707 sha256=94b1dc51c57e07d265b00bf1919799d1be6ccee4cb0bcd2bc85d4a9961c12ad6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1fk7gih4/wheels/f8/d9/cc/e2118e18bd1ec7721538676ef74360bcdfe48097bdb504595a\n",
            "Successfully built albumentations\n",
            "Installing collected packages: albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.3.0\n",
            "    Uninstalling albumentations-1.3.0:\n",
            "      Successfully uninstalled albumentations-1.3.0\n",
            "Successfully installed albumentations-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --user albumentations/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6wKtmbkXvrR",
        "outputId": "adcad46b-e0f5-4fda-ac9f-77dbafaa269b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.0\n"
          ]
        }
      ],
      "source": [
        "import albumentations\n",
        "print(albumentations.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R82KTAfb_HB"
      },
      "source": [
        "**Using Albumentations library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYIQsja5crqY"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Create a dictionary (named data) with image names as key and for each image,\n",
        "associate an internal dictionnary with keys \"labels\" and \"bboxes\"\n",
        "- labels is a list containing all labels detected in the image\n",
        "- bboxes is a flatten list of all anchor boxes positions of objects in the image\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "TRAIN_LABELS_DIR = \"ada-image-recognition-fiber/dataset/labels/train/\"\n",
        "\n",
        "label_and_bboxes = os.listdir(TRAIN_LABELS_DIR)\n",
        "data = dict()\n",
        "for file in label_and_bboxes:\n",
        "    path = os.path.join(TRAIN_LABELS_DIR, file)\n",
        "    name = file.split(\".\")[0]\n",
        "    data[name] = {}\n",
        "    with open(path, 'r') as f:\n",
        "        bboxes = list()\n",
        "        labels = list()\n",
        "        for line in f:\n",
        "            line = line.split()\n",
        "            labels.append(int(line[0]))\n",
        "            bboxes.append(list(map(float, line[1:])))\n",
        "        data[name][\"bboxes\"] = bboxes\n",
        "        data[name][\"labels\"] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDqVbULRfPdW"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "launch the pipeline\n",
        "source_directory : \"ada-image-recognition-fiber/dataset/images/train/\"\n",
        "bboxes : contains for each image in the source directory the bboes and the labels\n",
        "where: would be the new directory in the parent of the source and should be present in the labels dir as well (just the name for the augmented data folder)\n",
        "\"\"\"\n",
        "\n",
        "LABELS_DIR = \"ada-image-recognition-fiber/dataset/labels/\"\n",
        "IMAGE_DIR = \"ada-image-recognition-fiber/dataset/images/\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def augmentation_pipeline(transformation_fn, n_iter, source_directory, bboxes_data, augmented_data_dir, augmented_labels_dir):\n",
        "    files = os.listdir(source_directory)\n",
        "    for i, (name, data) in enumerate(bboxes_data.items()):\n",
        "        img_path = os.path.join(source_directory, name+\".jpg\")\n",
        "        #image = cv2.imread(img_path)\n",
        "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #transformed = transformation_fn(image=image, bboxes=data[\"bboxes\"], class_labels=data[\"labels\"])\n",
        "        image = Image.open(img_path)\n",
        "        transformed = transformation_fn(image=np.array(image), bboxes=data[\"bboxes\"], class_labels=data[\"labels\"])\n",
        "        transformed_image = transformed['image']\n",
        "        transformed_bboxes = transformed['bboxes']\n",
        "        transformed_class_labels = transformed['class_labels']\n",
        "        if len(transformed_class_labels) == 0:\n",
        "            continue\n",
        "        cv2.imwrite(os.path.join(augmented_data_dir, \"aug_\" + str(n_iter) + \"_\" + name + '.jpg'), transformed_image)\n",
        "    \n",
        "        str_label = \"\"\n",
        "        for lab, bb in zip(transformed_class_labels, transformed_bboxes):\n",
        "            str_label += f\"{lab} \" + \" \".join(map(str, bb)) + \"\\n\"\n",
        "        \n",
        "        with open(os.path.join(augmented_labels_dir, \"aug_\" + str(n_iter) + \"_\" + name + '.txt'), 'w') as f:\n",
        "             f.write(str_label)\n",
        "        print(\"iteration\", n_iter, \"image\", i+1, \"over\", len(bboxes_data))\n",
        "    print(\"Done for iteration\", n_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lUF5hhFjw9S",
        "outputId": "28d517ea-1754-4550-bfce-e059159f8398"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.local/lib/python3.9/site-packages/albumentations/augmentations/blur/transforms.py:184: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Prepare the pipeline of different transformations to perform for the augmentation\n",
        "\"\"\"\n",
        "\n",
        "import albumentations as A\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "transformations = [\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.Rotate(limit=(-10, 10), p=0.5),\n",
        "    A.Perspective(scale=(0.05, 0.1), p=0.5),\n",
        "    A.GridDistortion(p=0.5),\n",
        "    A.ElasticTransform(p=0.5),\n",
        "    A.RandomSnow(p=0.5),\n",
        "    A.RandomRain(p=0.5),\n",
        "    A.RandomFog(p=0.5),\n",
        "    A.RandomShadow(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=20, p=0.5),\n",
        "    # A.mixup(p=0.5),\n",
        "    #A.Cutout(num_holes=1, max_h_size=64, max_w_size=64, p=0.5),\n",
        "    #A.CoarseDropout(max_holes=4, max_height=32, max_width=32, min_holes=1, min_height=8, min_width=8, fill_value=0, p=0.2),\n",
        "    # A.RandomErasing(p=0.5),\n",
        "]\n",
        "\n",
        "fix_transformations = [\n",
        "    A.Resize(width=640, height=640),\n",
        "    A.OneOf([\n",
        "        A.Blur(blur_limit=3, p=0.5),\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "        A.MedianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.2),\n",
        "    A.OneOf([\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "        A.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "        A.CLAHE(clip_limit=(1, 4), p=0.5),\n",
        "    ], p=0.2)\n",
        "]\n",
        "\n",
        "n_transforms_per_image = 4\n",
        "n_augmentations_per_image = 8\n",
        "\n",
        "combinations = list(itertools.combinations(transformations, n_transforms_per_image))\n",
        "results = random.sample(combinations, n_augmentations_per_image)\n",
        "\n",
        "results = list(map(list, results))\n",
        "results = list(map(lambda x: fix_transformations + x, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RhZXt-MtpIqE"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "\n",
        "source_dir = \"ada-image-recognition-fiber/dataset/images/train/\"\n",
        "where = \"aug_train\"\n",
        "augmented_labels_dir = LABELS_DIR + where\n",
        "augmented_data_dir = IMAGE_DIR + where\n",
        "if os.path.exists(augmented_labels_dir):\n",
        "    shutil.rmtree(augmented_labels_dir)\n",
        "os.makedirs(augmented_labels_dir)\n",
        "if os.path.exists(augmented_data_dir):\n",
        "    shutil.rmtree(augmented_data_dir)\n",
        "os.makedirs(augmented_data_dir)\n",
        "\n",
        "\n",
        "def parallel_augmentation(n, results, source_dir, data):\n",
        "    transform = A.Compose(results[n], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], check_each_transform=False))\n",
        "    augmentation_pipeline(transform, n+1, source_dir, data, augmented_data_dir, augmented_labels_dir)\n",
        "    return None\n",
        "\n",
        "\n",
        "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "    futures = []\n",
        "    for n in range(n_augmentations_per_image):\n",
        "        future = executor.submit(parallel_augmentation, n, results, source_dir, data)\n",
        "        futures.append(future)\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        result = future.result()\n",
        "\n",
        "\n",
        "# for n in range(n_augmentations_per_image):\n",
        "#     transform = A.Compose(results[n], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], check_each_transform=False))\n",
        "#     augmentation_pipeline(transform, n+1, source_dir, data, augmented_data_dir, augmented_labels_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxJ7klibb97X"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def zip_folder(folder_path, zip_path):\n",
        "    \"\"\"\n",
        "    Compresses a folder into a ZIP archive.\n",
        "\n",
        "    :param folder_path: Path to the folder to be compressed.\n",
        "    :param zip_path: Path to the output ZIP archive.\n",
        "    \"\"\"\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
        "\n",
        "zip_folder('yolov5/', 'res_80_epochs_sgd.zip')\n",
        "# zip_folder('ada-image-recognition-fiber/dataset/images/aug_train/', 'aug_img.zip')\n",
        "# zip_folder('ada-image-recognition-fiber/dataset/labels/aug_train/', 'aug_lbl.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}